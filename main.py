import asyncio
import configparser
import aiohttp
import logging
import json
import csv
import re

# Read configuration
config = configparser.ConfigParser()
config.read('config.ini')

GRAPHQL_ENDPOINT = config['DEFAULT']['GraphQL_Endpoint']
TOKEN = config['DEFAULT']['Token']

# Headers for GraphQL requests
headers = {
    "Authorization": f"Bearer {TOKEN}",
    "Content-Type": "application/json"
}

# Set up logging
logging_level = getattr(logging, config['LOGGING']['Level'].upper(), None)
if not isinstance(logging_level, int):
    raise ValueError('Invalid log level: %s' % config['LOGGING']['Level'])

logging.basicConfig(filename='vulnerability_fetch_async.log', level=logging_level)


# Common Logic to execute GQL Query
async def execute_graphql_query(session, query, variables=None):
    payload = {'query': query}
    if variables is not None:
        payload['variables'] = variables
    # Log the request payload for debugging
    logging.debug(f"Sending GraphQL query: {json.dumps(payload, indent=2)}")
    async with session.post(GRAPHQL_ENDPOINT, json=payload, headers=headers) as response:
        response_text = await response.text()
        if response.status == 200:
            logging.debug(f"GraphQL query successful: {response_text}")
            return await response.json()
        else:
            logging.error(f"GraphQL query failed with status code {response.status}: {response_text}")
            return None


# Read queries from files
def read_query_from_file(file_path):
    with open(file_path, 'r') as file:
        return file.read()


query1 = read_query_from_file(config['QUERIES']['Query1_File'])
query2_template = read_query_from_file(config['QUERIES']['Query2_Template_File'])


# Logic to retrieve available subcategories
async def fetch_vulnerability_subcategories(session):
    subcategories = set()
    result = await execute_graphql_query(session, query1)
    if result:
        for item in result["data"]["vulnerabilitiesV3"]["results"]:
            subcategories.add(item["VULNERABILITY_SUB_CATEGORY"]["value"])
    return subcategories


# logic to fetch CVE details
async def fetch_vulnerability_details(session, subcategories):
    vulnerabilities = {}
    for subcategory in subcategories:
        # Manually add quotes around the subcategory value
        # Ensure to escape any internal quotes within the subcategory string itself
        formatted_subcategory = '"' + subcategory.replace('"', '\\"') + '"'
        formatted_subcategory = re.escape(subcategory)
        # Replace the placeholder in the query with the formatted subcategory value
        query_with_subcategory = query2_template.replace("PLACEHOLDER", formatted_subcategory)
        response = await execute_graphql_query(session, query_with_subcategory)
        if response:  # Check if response is not None
            data = response.get("data")
            if data and "vulnerabilitiesV32" in data and "results" in data["vulnerabilitiesV32"]:
                # Ensure subcategory exists in vulnerabilities dictionary
                vulnerabilities[subcategory] = vulnerabilities.get(subcategory, [])
                vulnerabilities[subcategory].extend(data["vulnerabilitiesV32"]["results"])
                logging.debug(f"Data for subcategory {subcategory}: {vulnerabilities[subcategory]}")
            else:
                logging.error(f"No valid data found for subcategory {subcategory}. Response data: {data}")
        else:
            logging.error(f"Invalid response for subcategory {subcategory}")

    # Export to CSV
    export_to_csv(vulnerabilities)
    return vulnerabilities


# Logic to export the vulnerabilities to a CSV
def export_to_csv(vulnerabilities, filename="vulnerabilities.csv"):
    try:
        with open(filename, mode='w', newline='', encoding='utf-8') as file:
            writer = csv.writer(file)

            # Write the header
            header = ["Vulnerability ID", "API ID", "Vulnerability Category", "Status", "Affected Span Path",
                      "Test IDs",
                      "Last Seen Timestamp", "Created Timestamp", "Closed Timestamp", "Sources", "Entity ID",
                      "Entity Name",
                      "Risk Score", "Risk Score Category", "Service ID", "Service Name"]
            writer.writerow(header)
            # Write the data
            for subcategory, items in vulnerabilities.items():
                for item in items:
                    # Initialize default values for all fields
                    vulnerability_id = item.get("VULNERABILITY_ID", {}).get("value", "N/A")
                    api_id = item.get("API_ID", {}).get("value", "N/A")
                    vulnerability_category = item.get("VULNERABILITY_CATEGORY", {}).get("value", "N/A")
                    status = item.get("STATUS", {}).get("value", "N/A")
                    affected_span_path = ','.join(item.get("AFFECTED_SPAN_PATH", {}).get("value", [])) if item.get(
                        "AFFECTED_SPAN_PATH") else "N/A"
                    test_ids = ','.join(item.get("TEST_IDS", {}).get("value", [])) if item.get("TEST_IDS") else "N/A"
                    last_seen_timestamp = item.get("LAST_SEEN_TIMESTAMP_MILLIS", {}).get("value", "N/A")
                    created_timestamp = item.get("CREATED_TIMESTAMP_MILLIS", {}).get("value", "N/A")
                    closed_timestamp = item.get("CLOSED_TIMESTAMP_MILLIS", {}).get("value", "N/A") if item.get(
                        "CLOSED_TIMESTAMP_MILLIS") else "N/A"
                    sources = ','.join(item.get("SOURCES", {}).get("value", [])) if item.get("SOURCES") else "N/A"

                    # Handle potential NoneType for 'entity'
                    entity = item.get("entity")
                    if entity:
                        entity_id = entity.get("id", "N/A")
                        entity_name = entity.get("name", "N/A")
                        risk_score = entity.get("riskScore", "N/A")
                        risk_score_category = entity.get("riskScoreCategory", "N/A")
                        service_id = entity.get("serviceId", "N/A")
                        service_name = entity.get("serviceName", "N/A")
                    else:
                        entity_id = entity_name = risk_score = risk_score_category = service_id = service_name = "N/A"

                    row = [
                        vulnerability_id,
                        api_id,
                        vulnerability_category,
                        status,
                        affected_span_path,
                        test_ids,
                        last_seen_timestamp,
                        created_timestamp,
                        closed_timestamp,
                        sources,
                        entity_id,
                        entity_name,
                        risk_score,
                        risk_score_category,
                        service_id,
                        service_name
                    ]
                    writer.writerow(row)

        logging.info(f"CSV export completed successfully. File: {filename}")
    except Exception as e:
        logging.error(f"Error during CSV export: {e}")


async def main():
    async with aiohttp.ClientSession() as session:
        subcategories = await fetch_vulnerability_subcategories(session)
        logging.info(f"Fetched {len(subcategories)} subcategories.")

        vulnerabilities = await fetch_vulnerability_details(session, subcategories)
        for subcategory, details in vulnerabilities.items():
            logging.info(f"Fetched {len(details)} vulnerabilities for subcategory: {subcategory}")


if __name__ == "__main__":
    asyncio.run(main())
